{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Text Categorization Competition\n",
    "\n",
    "In this project I will be using a BERT model for classifying text data, as part of the AI Crowd NLP competition.\n",
    "\n",
    "I will be using the ktrain library, which works with Tensorflow 2.0. I found this high-level library to be extremely useful for quickly building up a great BERT model, with state of the art prediction capabilities. This project was done using Amazon's Sagemaker and an Amazon Web Service's GPU server. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Contest: Transfer Learning for International Crisis Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this contest is to improve the text classification algorithms used within the DEEP humanitarian information platform. To quote their website:\n",
    "\n",
    "\"The aim of the platform is to provide insights from years of historical and in-crisis humanitarian text data. The platform allows users to upload documents and classify text snippets according to predefined humanitarian target labels, grouped into and referred to as analytical frameworks. DEEP is now successfully functional in several international humanitarian organizations and the United Nations across the globe.\"\n",
    "\n",
    "Currently, multiple organizations use the DEEP platform and each has a separate classification algorithm with varying degrees of success and which are not trained across other organizations. The aim of this project is to build a unified algorithm which both performs better and is generalizable enough to work across all organizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Categories: 12 Different Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Agriculture\n",
    "\n",
    "(2) Cross: short form of Cross-sectoral; areas of humanitarian response that require action in more than one sector. For example malnutrition requires humanitarian interventions in health, access to food, access to basic hygiene items and clean water, and access to non-food items such as bottles to feed infants.\n",
    "\n",
    "(3) Education\n",
    "\n",
    "(4) Food\n",
    "\n",
    "(5) Health\n",
    "\n",
    "(6) Livelihood: Access to employment and income\n",
    "\n",
    "(7) Logistics: Any logistical support needed to carry out humanitarian activities e.g. air transport, satellite phone \n",
    "connection etc.\n",
    "\n",
    "(8) NFI: Non-food items needed in daily life that are not food such as bedding, mattrassess, jerrycans, coal or oil for heating\n",
    "\n",
    "(9) Nutrition\n",
    "\n",
    "(10) Protection\n",
    "\n",
    "(11) Shelter\n",
    "\n",
    "(12) WASH (Water, Sanitation and Hygiene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the contest has already finished while I am writing this, I never got the chance to try a BERT model. I wanted to build this notebook as a challenge to myself, to see if I can beat my previous best performance of 78% training accuracy and 69% validation accuracy. I am confident that BERT can help me achieve this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, I need to load a Tensorflow 1.14 or standard Python 3 Sagemaker notebook, then use pip to upgrade to Tensorflow 2.0. In other notebooks, I also tried loading Tensorflow 2.0 via a docker image, but this method below worked the best for me. A major reason why I am using Amazon Web Services for this project is having access to their powerful graphics processor units, which I do not have on my personal computer.\n",
    "\n",
    "The data cleaning was done in a different notebook then loaded into this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Using cached https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 19.3.1\n",
      "    Uninstalling pip-19.3.1:\n",
      "      Successfully uninstalled pip-19.3.1\n",
      "Successfully installed pip-20.0.2\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-45.1.0-py3-none-any.whl (583 kB)\n",
      "\u001b[31mERROR: tensorflow-serving-api 1.15.0 requires tensorflow~=1.15.0, which is not installed.\u001b[0m\n",
      "Installing collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 41.6.0\n",
      "    Uninstalling setuptools-41.6.0:\n",
      "      Successfully uninstalled setuptools-41.6.0\n",
      "Successfully installed setuptools-45.1.0\n",
      "Processing /home/ec2-user/.cache/pip/wheels/3d/e7/4b/6f839c9443003c6fabfc286d29228050d8e2e9b0d1d50399d0/ktrain-0.8.3-cp36-none-any.whl\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ktrain) (0.14.0)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/63/dc/87/3260cb91f3aa32c0f85c5375429a30c8fd988bbb48f5ee21b0/keras_bert-0.80.0-cp36-none-any.whl\n",
      "Processing /home/ec2-user/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe/langdetect-1.0.7-cp36-none-any.whl\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ktrain) (17.1)\n",
      "Collecting fastprogress>=0.1.21\n",
      "  Using cached fastprogress-0.2.2-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests in /home/ec2-user/.local/lib/python3.6/site-packages (from ktrain) (2.22.0)\n",
      "Collecting transformers\n",
      "  Using cached transformers-2.3.0-py3-none-any.whl (447 kB)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68/seqeval-0.0.12-cp36-none-any.whl\n",
      "Processing /home/ec2-user/.cache/pip/wheels/81/dc/bb/fbde77ddcbf8d5a04787faf6cc9f1edf4c70a67961d7c75abf/networkx-2.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: bokeh in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ktrain) (1.0.4)\n",
      "Collecting cchardet\n",
      "  Using cached cchardet-2.1.5-cp36-cp36m-manylinux1_x86_64.whl (241 kB)\n",
      "Requirement already satisfied: pandas<1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ktrain) (0.24.2)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/af/e4/8e/5fdd61a6b45032936b8f9ae2044ab33e61577950ce8e0dec29/jieba-0.42.1-cp36-none-any.whl\n",
      "Requirement already satisfied: ipython in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ktrain) (6.4.0)\n",
      "Requirement already satisfied: scikit-learn==0.21.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ktrain) (0.21.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ktrain) (3.0.3)\n",
      "Collecting tensorflow-datasets\n",
      "  Using cached tensorflow_datasets-2.0.0-py3-none-any.whl (3.1 MB)\n",
      "Requirement already satisfied: Keras in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras-bert->ktrain) (2.2.4)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/.local/lib/python3.6/site-packages (from keras-bert->ktrain) (1.18.1)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/a3/c5/9a/5a5130240be614a7a6fa786765d7692ae97f82601e2161bb56/keras_transformer-0.31.0-cp36-none-any.whl\n",
      "Requirement already satisfied: six in /home/ec2-user/.local/lib/python3.6/site-packages (from langdetect->ktrain) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from packaging->ktrain) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->ktrain) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->ktrain) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->ktrain) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->ktrain) (1.23)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2020.1.8-cp36-cp36m-manylinux2010_x86_64.whl (689 kB)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from transformers->ktrain) (1.11.5)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422/sacremoses-0.0.38-cp36-none-any.whl\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.42.0-py2.py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from networkx==2.3->ktrain) (4.3.0)\n",
      "Requirement already satisfied: pillow>=4.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from bokeh->ktrain) (5.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from bokeh->ktrain) (2.7.3)\n",
      "Requirement already satisfied: tornado>=4.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from bokeh->ktrain) (5.0.2)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from bokeh->ktrain) (2.10)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from bokeh->ktrain) (3.12)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas<1.0->ktrain) (2018.4)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->ktrain) (45.1.0)\n",
      "Requirement already satisfied: pickleshare in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->ktrain) (0.7.4)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->ktrain) (0.8.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->ktrain) (1.0.15)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->ktrain) (4.3.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->ktrain) (0.12.0)\n",
      "Requirement already satisfied: pygments in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->ktrain) (2.2.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->ktrain) (4.5.0)\n",
      "Requirement already satisfied: backcall in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from ipython->ktrain) (0.1.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from scikit-learn==0.21.3->ktrain) (1.4.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/19/49/34/c3c1e78bcb954c49e5ec0d31784fe63d14d427f316b12fbde9/promise-2.3-cp36-none-any.whl\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-datasets->ktrain) (3.11.2)\n",
      "Requirement already satisfied: absl-py in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-datasets->ktrain) (0.9.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/ec2-user/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7/dill-0.3.1.1-cp36-none-any.whl\n",
      "Collecting tensorflow-metadata\n",
      "  Using cached tensorflow_metadata-0.21.0-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: wrapt in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-datasets->ktrain) (1.11.2)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-datasets->ktrain) (18.1.0)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-datasets->ktrain) (1.1.0)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94/future-0.18.2-py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /home/ec2-user/.local/lib/python3.6/site-packages (from Keras->keras-bert->ktrain) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/.local/lib/python3.6/site-packages (from Keras->keras-bert->ktrain) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ec2-user/.local/lib/python3.6/site-packages (from Keras->keras-bert->ktrain) (1.0.8)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e/keras_multi_head-0.22.0-cp36-none-any.whl\n",
      "Processing /home/ec2-user/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866/keras_embed_sim-0.7.0-cp36-none-any.whl\n",
      "Processing /home/ec2-user/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032/keras_pos_embd-0.11.0-cp36-none-any.whl\n",
      "Processing /home/ec2-user/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667/keras_layer_normalization-0.14.0-cp36-none-any.whl\n",
      "Processing /home/ec2-user/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b/keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3->transformers->ktrain) (0.3.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3->transformers->ktrain) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3->transformers->ktrain) (1.14.5)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from sacremoses->transformers->ktrain) (6.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from Jinja2>=2.7->bokeh->ktrain) (1.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython->ktrain) (0.1.7)\n",
      "Requirement already satisfied: ipython_genutils in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n",
      "Requirement already satisfied: parso>=0.2.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from jedi>=0.10->ipython->ktrain) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.5.2)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/2c/f9/7f/6eb87e636072bf467e25348bbeb96849333e6a080dca78f706/googleapis_common_protos-1.51.0-cp36-none-any.whl\n",
      "Processing /home/ec2-user/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694/keras_self_attention-0.41.0-cp36-none-any.whl\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.5->boto3->transformers->ktrain) (0.14)\n",
      "Installing collected packages: keras-self-attention, keras-multi-head, keras-embed-sim, keras-pos-embd, keras-layer-normalization, keras-position-wise-feed-forward, keras-transformer, keras-bert, langdetect, fastprogress, regex, sentencepiece, tqdm, sacremoses, transformers, seqeval, networkx, cchardet, jieba, promise, dill, googleapis-common-protos, tensorflow-metadata, future, tensorflow-datasets, ktrain\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.1\n",
      "    Uninstalling networkx-2.1:\n",
      "      Successfully uninstalled networkx-2.1\n",
      "Successfully installed cchardet-2.1.5 dill-0.3.1.1 fastprogress-0.2.2 future-0.18.2 googleapis-common-protos-1.51.0 jieba-0.42.1 keras-bert-0.80.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.31.0 ktrain-0.8.3 langdetect-1.0.7 networkx-2.3 promise-2.3 regex-2020.1.8 sacremoses-0.0.38 sentencepiece-0.1.85 seqeval-0.0.12 tensorflow-datasets-2.0.0 tensorflow-metadata-0.21.0 tqdm-4.42.0 transformers-2.3.0\n",
      "Collecting git+https://github.com/amaiya/eli5@tfkeras_0_10_1\n",
      "  Cloning https://github.com/amaiya/eli5 (to revision tfkeras_0_10_1) to /tmp/pip-req-build-j3n2br8n\n",
      "  Running command git clone -q https://github.com/amaiya/eli5 /tmp/pip-req-build-j3n2br8n\n",
      "  Running command git checkout -b tfkeras_0_10_1 --track origin/tfkeras_0_10_1\n",
      "  Switched to a new branch 'tfkeras_0_10_1'\n",
      "  Branch tfkeras_0_10_1 set up to track remote branch tfkeras_0_10_1 from origin.\n",
      "Requirement already satisfied: attrs>16.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from eli5==0.10.1) (18.1.0)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from eli5==0.10.1) (2.10)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from eli5==0.10.1) (1.18.1)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/.local/lib/python3.6/site-packages (from eli5==0.10.1) (1.4.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/.local/lib/python3.6/site-packages (from eli5==0.10.1) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from eli5==0.10.1) (0.21.3)\n",
      "Collecting graphviz\n",
      "  Using cached graphviz-0.13.2-py2.py3-none-any.whl (17 kB)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/9c/9b/f4/eb243fdb89676ec00588e8c54bb54360724c06e7fafe95278e/tabulate-0.8.6-cp36-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from jinja2->eli5==0.10.1) (1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-learn>=0.18->eli5==0.10.1) (0.14.0)\n",
      "Building wheels for collected packages: eli5\n",
      "  Building wheel for eli5 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for eli5: filename=eli5-0.10.1-py2.py3-none-any.whl size=105885 sha256=34b5ce3f6e199e942abf8c3be27f6ede72a6af56803fa52c95090715b0611c18\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8vuyzjde/wheels/93/23/c2/479f99e6e981887ac70af72d4ff763471acf7184d1b80a9268\n",
      "Successfully built eli5\n",
      "Installing collected packages: graphviz, tabulate, eli5\n",
      "Successfully installed eli5-0.10.1 graphviz-0.13.2 tabulate-0.8.6\n",
      "Collecting git+https://github.com/amaiya/stellargraph@no_tf_dep_082\n",
      "  Cloning https://github.com/amaiya/stellargraph (to revision no_tf_dep_082) to /tmp/pip-req-build-jsciqsia\n",
      "  Running command git clone -q https://github.com/amaiya/stellargraph /tmp/pip-req-build-jsciqsia\n",
      "  Running command git checkout -b no_tf_dep_082 --track origin/no_tf_dep_082\n",
      "  Switched to a new branch 'no_tf_dep_082'\n",
      "  Branch no_tf_dep_082 set up to track remote branch no_tf_dep_082 from origin.\n",
      "Requirement already satisfied: numpy>=1.14 in /home/ec2-user/.local/lib/python3.6/site-packages (from stellargraph==0.8.2) (1.18.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from stellargraph==0.8.2) (1.4.1)\n",
      "Requirement already satisfied: networkx<2.4,>=2.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from stellargraph==0.8.2) (2.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit_learn>=0.20 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from stellargraph==0.8.2) (0.21.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from stellargraph==0.8.2) (3.0.3)\n",
      "Requirement already satisfied: pandas>=0.24 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from stellargraph==0.8.2) (0.24.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from networkx<2.4,>=2.2->stellargraph==0.8.2) (4.3.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit_learn>=0.20->stellargraph==0.8.2) (0.14.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=2.2->stellargraph==0.8.2) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=2.2->stellargraph==0.8.2) (2.7.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=2.2->stellargraph==0.8.2) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=2.2->stellargraph==0.8.2) (2.2.0)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas>=0.24->stellargraph==0.8.2) (2018.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/.local/lib/python3.6/site-packages (from cycler>=0.10->matplotlib>=2.2->stellargraph==0.8.2) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->stellargraph==0.8.2) (45.1.0)\n",
      "Building wheels for collected packages: stellargraph\n",
      "  Building wheel for stellargraph (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stellargraph: filename=stellargraph-0.8.2-py3-none-any.whl size=141652 sha256=6f91834a123d945b821c4abda513aa91afa101b59a91605f163be867567ca661\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mwnjipr6/wheels/9d/18/94/4155a499aea4ffd22b73a1983d594d4f4118e107068a30142f\n",
      "Successfully built stellargraph\n",
      "Installing collected packages: stellargraph\n",
      "Successfully installed stellargraph-0.8.2\n"
     ]
    }
   ],
   "source": [
    "# upgrading pip and setuptools to ensure everything installs smoothly\n",
    "\n",
    "! pip install --upgrade pip\n",
    "! pip install --upgrade setuptools\n",
    "\n",
    "# installing the ktrain library we will be using to train our bert model\n",
    "\n",
    "! pip install ktrain\n",
    "\n",
    "# installing dependencies for ktrain\n",
    "\n",
    "! pip install git+https://github.com/amaiya/eli5@tfkeras_0_10_1\n",
    "! pip install git+https://github.com/amaiya/stellargraph@no_tf_dep_082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow-gpu in /home/ec2-user/.local/lib/python3.6/site-packages (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.2.0,>=2.1.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu) (0.31.1)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (3.11.2)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (1.26.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorflow-gpu) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /home/ec2-user/.local/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (45.1.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /home/ec2-user/.local/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.4.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /home/ec2-user/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "# upgrade to Tensorflow 2.0 for gpu\n",
    "\n",
    "! pip install --user --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Keras version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "# importing the ktrain library and pandas for preprocessing\n",
    "\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set: 8619\n",
      "size of validation set: 958\n"
     ]
    }
   ],
   "source": [
    "# loading data from csv file, this file was cleaned in another notebook\n",
    "# datasets will be separated into a train and test, with just the text column and the category it belongs to\n",
    "\n",
    "# load data\n",
    "data = pd.read_csv(\"train_no_dummies.csv\")\n",
    "\n",
    "# splitting and shuffling train and test, test size 10%\n",
    "train, test = train_test_split(data, test_size=0.1, shuffle=True, random_state=2)\n",
    "\n",
    "print('size of training set: %s' % (len(train['text'])))\n",
    "print('size of validation set: %s' % (len(test['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>The management of Mitiga Airport has confirmed...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>And in Venezuelaestán reappearing controladasc...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>Reportedly, transportation costs, accommodatio...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>As for distance, 60% of households are less th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8094</th>\n",
       "      <td>[Seasonal calendar] Climate conditions, Hazard...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "2521  The management of Mitiga Airport has confirmed...       2\n",
       "4646  And in Venezuelaestán reappearing controladasc...       5\n",
       "825   Reportedly, transportation costs, accommodatio...      10\n",
       "5196  As for distance, 60% of households are less th...       2\n",
       "8094  [Seasonal calendar] Climate conditions, Hazard...       6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the first 5 rows of training data\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2521    The management of Mitiga Airport has confirmed...\n",
       "4646    And in Venezuelaestán reappearing controladasc...\n",
       "825     Reportedly, transportation costs, accommodatio...\n",
       "5196    As for distance, 60% of households are less th...\n",
       "8094    [Seasonal calendar] Climate conditions, Hazard...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting data into correct format for preprocessing\n",
    "x_train = train.text\n",
    "y_train = train.labels\n",
    "x_test = test.text\n",
    "y_test = test.labels\n",
    "\n",
    "# viewing some training examples before preprocessing\n",
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext: a fastText-like model [http://arxiv.org/pdf/1607.01759.pdf]\n",
      "logreg: logistic regression using a trainable Embedding layer\n",
      "nbsvm: NBSVM model [http://www.aclweb.org/anthology/P12-2018]\n",
      "bigru: Bidirectional GRU with pretrained word vectors [https://arxiv.org/abs/1712.09405]\n",
      "standard_gru: simple 2-layer GRU with randomly initialized embeddings\n",
      "bert: Bidirectional Encoder Representations from Transformers (BERT) [https://arxiv.org/abs/1810.04805]\n",
      "distilbert: distilled, smaller, and faster BERT from Hugging Face [https://arxiv.org/abs/1910.01108]\n"
     ]
    }
   ],
   "source": [
    "text.print_text_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we are using a distilbert model, a quicker training bert model that still works great\n",
    "\n",
    "# labels fall into one of 12 categories\n",
    "categories = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "# using ktrain's preprocessing function, I had to specify lang='en' (English) for the function to work\n",
    "trn, val, preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n",
    "                                          x_test=x_test, y_test=y_test,\n",
    "                                          class_names=categories,\n",
    "                                          preprocess_mode='distilbert',\n",
    "                                          lang='en',\n",
    "                                          maxlen=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 350\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# defining model and wrapping in learner\n",
    "\n",
    "model = text.text_classifier('distilbert', train_data=trn, preproc=preproc)\n",
    "\n",
    "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "distilbert (TFDistilBertMain multiple                  66362880  \n",
      "_________________________________________________________________\n",
      "pre_classifier (Dense)       multiple                  590592    \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  9997      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         multiple                  0         \n",
      "=================================================================\n",
      "Total params: 66,963,469\n",
      "Trainable params: 66,963,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# viewing the layers of the model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 3e-05...\n",
      "Train for 1437 steps, validate for 160 steps\n",
      "1437/1437 [==============================] - 676s 470ms/step - loss: 1.0504 - accuracy: 0.6942 - val_loss: 0.7123 - val_accuracy: 0.7850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb18c0e5048>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model to data\n",
    "\n",
    "learner.fit_onecycle(3e-5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a great first epoch! It is already much more accurate than my previous best model, with the validation at 78.5%. My previous best model only had a validation accuracy of 69%. Surprisingly, the training dataset's accuracy is currently lower than the val data after one epoch (69% on training and 79% on val). There is still much more room for improvement on training set accuracy with continued training. We will train for two more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 3e-05...\n",
      "Train for 1437 steps, validate for 160 steps\n",
      "Epoch 1/2\n",
      "1437/1437 [==============================] - 667s 464ms/step - loss: 0.5445 - accuracy: 0.8468 - val_loss: 0.7540 - val_accuracy: 0.7745\n",
      "Epoch 2/2\n",
      "1437/1437 [==============================] - 666s 464ms/step - loss: 0.4144 - accuracy: 0.8836 - val_loss: 0.6725 - val_accuracy: 0.8058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb0c252a4e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(3e-5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to see that after two more epochs, accuracy on the training dataset dramatically improved, but the validation dataset decreased after the second epoch then slightly improved in the third, up to 80.6%. This may be close to the best we can achieve with this model and this data set. Any further training and we run the risk of overfitting. I am sure there is much more fine-tuning that can be done with this project, including hyperparameter tuning and trying other BERT model variations, but for me this is a good stopping point. I am extremely happy with the improvements that the mighty BERT model helped me achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions On New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will see how the model performs on sample text, a real example from the DEEP platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = ktrain.get_predictor(model, preproc)\n",
    "\n",
    "predictor.predict(\"Data revealed that the majority (35 out of 46) of the restaurants and tea shops are cooking by using wood fuel in mud stove, while 16 of them are using LPG and LPG Stove\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicted the highest probability category of 9: Nutrition. This is a very reasonable label for a post about cooking methods, however if we were applying multiple labels, then 9: Food or also even 5: Health would also be good labels as well. In reality, the DEEP system does apply multiple labels, but they do not for purposes of this competition.\n",
    "\n",
    "Thank you BERT!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
