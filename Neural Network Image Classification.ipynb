{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this short project is to create an image classification model. Each row in my dataset is an image. The dataset has 63 columns and the values represent different degrees of shading for each pixel in the image. For predictions, I will compare using a clustering method to a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating training and target dataframes\n",
    "\n",
    "train = load_digits()\n",
    "target = pd.DataFrame(train.target)\n",
    "target[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2     3     4     5    6    7    8    9  ...    54   55   56  \\\n",
       "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0 ...   5.0  0.0  0.0   \n",
       "\n",
       "    57   58    59    60    61   62   63  \n",
       "0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame(train.data)\n",
    "train_data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22a85aff4e0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image = train_data.iloc[0]\n",
    "np_image = first_image.values.reshape(8,8)\n",
    "plt.imshow(np_image, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting sample rows to images and storing in a dictionary\n",
    "\n",
    "rows = [0, 100, 200, 300, 1000, 1100, 1200, 1300]\n",
    "dictionary = {}\n",
    "\n",
    "for row in rows:\n",
    "    image = train_data.iloc[row]\n",
    "    dictionary[row] = image.values.reshape(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22a85ae8be0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## creating a visualization of sample images\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2,4,1)\n",
    "ax1.imshow(dictionary[0], cmap='gray_r')\n",
    "ax2 = fig.add_subplot(2,4,2)\n",
    "ax2.imshow(dictionary[100], cmap='gray_r')\n",
    "ax3 = fig.add_subplot(2,4,3)\n",
    "ax3.imshow(dictionary[200], cmap='gray_r')\n",
    "ax4 = fig.add_subplot(2,4,4)\n",
    "ax4.imshow(dictionary[300], cmap='gray_r')\n",
    "ax5 = fig.add_subplot(2,4,5)\n",
    "ax5.imshow(dictionary[1000], cmap='gray_r')\n",
    "ax6 = fig.add_subplot(2,4,6)\n",
    "ax6.imshow(dictionary[1100], cmap='gray_r')\n",
    "ax7 = fig.add_subplot(2,4,7)\n",
    "ax7.imshow(dictionary[1200], cmap='gray_r')\n",
    "ax8 = fig.add_subplot(2,4,8)\n",
    "ax8.imshow(dictionary[1300], cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0\n",
      "0     0\n",
      "100   4\n",
      "200   1\n",
      "300   7\n",
      "1000  1\n",
      "1100  9\n",
      "1200  7\n",
      "1300  3\n"
     ]
    }
   ],
   "source": [
    "## verify above images with target column\n",
    "\n",
    "print(target.iloc[rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These eight images are handwritten numbers. By comparing what we see in the images with the target column, we can see how our classification model will need to understand various handwriting styles and still provide an accurate prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a combined dataframe then splitting for training and testing\n",
    "\n",
    "train_data['numbers'] = target\n",
    "shuffled = train_data.sample(frac=1, random_state=1)\n",
    "half = int(len(shuffled) / 2)\n",
    "train = shuffled.loc[:half].copy()\n",
    "test = shuffled.loc[half:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8059023836549376"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating functions for a k-nearest neighbors classifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features = shuffled.drop(['numbers'], axis=1).columns\n",
    "\n",
    "def train_knn(data, k):\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    knn.fit(data[features], data['numbers'])\n",
    "    return knn\n",
    "\n",
    "def test_knn(test_data, model):\n",
    "    test_data['predictions'] = model.predict(test_data[features])\n",
    "    return test_data\n",
    "\n",
    "knn = train_knn(train, 3)\n",
    "tested = test_knn(test, knn)\n",
    "accuracy_score(tested['numbers'], tested['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 neighbors and 4 folds avg_accuracy: 0.9821912892848305\n",
      "3 neighbors and 4 folds avg_accuracy: 0.9872011878247959\n",
      "4 neighbors and 4 folds avg_accuracy: 0.9833073496659243\n",
      "5 neighbors and 4 folds avg_accuracy: 0.9849777282850779\n",
      "6 neighbors and 4 folds avg_accuracy: 0.9827517941103686\n",
      "7 neighbors and 4 folds avg_accuracy: 0.9844221727295223\n",
      "8 neighbors and 4 folds avg_accuracy: 0.9805270972531551\n",
      "9 neighbors and 4 folds avg_accuracy: 0.9827567433803515\n"
     ]
    }
   ],
   "source": [
    "## using k-fold cross validation with 4 folds\n",
    "\n",
    "def cross_validate(data, k):\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=2)\n",
    "    accuracies = []\n",
    "    model = KNeighborsClassifier(k)\n",
    "    features = data.drop(['numbers'], axis=1).columns\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train, test = data.iloc[train_index], data.iloc[test_index]\n",
    "        model.fit(train[features], train['numbers'])\n",
    "        predictions = model.predict(test[features])\n",
    "        accuracy = accuracy_score(test['numbers'], predictions)\n",
    "        accuracies.append(accuracy)\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    print(k, \"neighbors and 4 folds avg_accuracy:\", avg_accuracy)\n",
    "    return avg_accuracy\n",
    "\n",
    "for i in range(2, 10):\n",
    "    cross_validate(train_data, k=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy using k-fold cross validation drastically improved. This could be because the KFold function trains itself on much more of the dataset than simply splitting it in half. The number of neighbors used seems to have a relatively minor affect on accuracy, but the top result is 3 neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Neural Network\n",
    "\n",
    "Next I will train a neural network on the data including varying the numbers of neurons in the single hidden layer and using 4-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brode\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\brode\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\brode\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 neurons 0.9360133630289533\n",
      "16 neurons 0.9476961148230636\n",
      "32 neurons 0.9543706178338695\n",
      "64 neurons 0.9591001608512744\n",
      "128 neurons 0.9624939371442712\n",
      "256 neurons 0.9650344386702961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9360133630289533,\n",
       " 0.9476961148230636,\n",
       " 0.9543706178338695,\n",
       " 0.9591001608512744,\n",
       " 0.9624939371442712,\n",
       " 0.9650344386702961]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## neural network model with one hidden layer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def nn_classifier(data):\n",
    "    neurons = [8, 16, 32, 64, 128, 256]\n",
    "    nn_accuracies = []\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=2)\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for n in neurons:\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(n,), activation='relu', max_iter=1000)\n",
    "\n",
    "        # include 4 fold validation\n",
    "        for train_index, test_index in kf.split(data):\n",
    "            train, test = data.iloc[train_index], data.iloc[test_index]\n",
    "            mlp.fit(train[features], train['numbers'])\n",
    "            nn_predictions = mlp.predict(test[features])\n",
    "            accuracy = accuracy_score(test['numbers'], nn_predictions)\n",
    "            fold_accuracies.append(accuracy)\n",
    "            \n",
    "        avg_accuracy = np.mean(fold_accuracies)\n",
    "        nn_accuracies.append(avg_accuracy)\n",
    "        print(n, \"neurons\", avg_accuracy)\n",
    "        \n",
    "    return nn_accuracies\n",
    "\n",
    "nn_classifier(shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With one hidden layer in my neural network, as we increased the number of neurons, the accuracy improved accordingly. 256 neurons brings us an accuracy of 96.7%, compared to 98.7% for the best knn classifier. Next I will try using 256 neurons in two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 neurons and 2 layers 0.9782949764909675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9782949764909675]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## increasing the neural network to 2 hidden layers and 256 neurons in each\n",
    "\n",
    "def nn_classifier(data, n, k):\n",
    "    nn_accuracies = []\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=2)\n",
    "    fold_accuracies = []\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(n,n), activation='relu', max_iter=1000)\n",
    "\n",
    "    # include 4 fold validation\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train, test = data.iloc[train_index], data.iloc[test_index]\n",
    "        mlp.fit(train[features], train['numbers'])\n",
    "        nn_predictions = mlp.predict(test[features])\n",
    "        accuracy = accuracy_score(test['numbers'], nn_predictions)\n",
    "        fold_accuracies.append(accuracy)\n",
    "            \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    nn_accuracies.append(avg_accuracy)\n",
    "    print(\"256 neurons and 2 layers\", avg_accuracy)    \n",
    "    return nn_accuracies\n",
    "\n",
    "nn_classifier(shuffled, 256, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 neurons in 3 hidden layers 0.9438089929394277\n",
      "64 neurons in 3 hidden layers 0.9602211073950205\n",
      "128 neurons in 3 hidden layers 0.9664350303480739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9438089929394277, 0.9602211073950205, 0.9664350303480739]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## modifying neural networks to 3 hidden layers, varying neurons in each, and 6 folds for validation\n",
    "## 3 model with 3 hidden layers of 10, 64, and 128 neurons\n",
    "\n",
    "def nn_classifier(data, k):\n",
    "    neurons = [10, 64, 128]\n",
    "    nn_accuracies = []\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=2)\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for n in neurons:\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(n,n,n), activation='relu', max_iter=1000)\n",
    "\n",
    "        # include 6 fold validation\n",
    "        for train_index, test_index in kf.split(data):\n",
    "            train, test = data.iloc[train_index], data.iloc[test_index]\n",
    "            mlp.fit(train[features], train['numbers'])\n",
    "            nn_predictions = mlp.predict(test[features])\n",
    "            accuracy = accuracy_score(test['numbers'], nn_predictions)\n",
    "            fold_accuracies.append(accuracy)\n",
    "            \n",
    "        avg_accuracy = np.mean(fold_accuracies)\n",
    "        nn_accuracies.append(avg_accuracy)\n",
    "        print(n, \"neurons in 3 hidden layers\", avg_accuracy)\n",
    "        \n",
    "    return nn_accuracies\n",
    "\n",
    "nn_classifier(shuffled, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By increasing the hidden layers and number of neurons in each, we actually achieved a lower accuracy score than the simplier model of two hidden layers. I believe we are overfitting the model and reached a point of diminishing returns as the model becomes too complex. This was interesting to compare with a clustering method, which actually produced roughly 1% more accuracy than my best neural network model. Sometimes the tried and true methods are still the most useful at achieving one's goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
